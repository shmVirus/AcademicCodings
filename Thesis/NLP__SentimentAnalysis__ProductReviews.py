# -*- coding: utf-8 -*-
"""Thesis__NLP__ProductReviewsSentimentAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ETdGASBWGJZ9gBu6xxOnT2EMPsHVcDrw
"""

import warnings     #: to supress warnings

warnings.filterwarnings("ignore")   #: suppress all warnings
# warnings.filterwarnings("default")  #: reset the warnings filter

import pandas as pd #: to manipulate data

#: load the CSV file containing the reviews
product_reviews = pd.read_csv('/content/dataset/ProductReviews.csv')
# product_reviews = product_reviews.sample(frac=1, random_state=42)                   #: suffling data
# product_reviews.to_csv('/content/dataset/ShuffledProductReviews.csv', index=False)  #: saving shuffled data
# product_reviews = pd.read_csv('/content/dataset/ShuffledProductReviews.csv')
display(product_reviews)

import numpy as np      #: to manipulate data
import pandas as pd     #: to manipulate data
from sklearn.metrics import cohen_kappa_score   #: to calculate similarity among annotators
import matplotlib.pyplot as plt     #: for ploting figures
import seaborn as sns               #: for visualization

#: list of annotator columns
annotator_columns = ['Annotator_Sakib', 'Annotator_Sabbir']

#: agreements and disagreements among annotators
agreements = np.sum((product_reviews[annotator_columns] == product_reviews[annotator_columns[0]]).all(axis=1))
total_items = len(product_reviews)
disagreements = total_items - agreements

#: pairwise Cohen's Kappa scores
pairwise_kappas = []
annotators = []
for i, annotator1 in enumerate(annotator_columns):
    for annotator2 in annotator_columns[i + 1:]:
        annotator1_name = annotator1.split('_')[1]  #: keeping only annotator name"
        annotator2_name = annotator2.split('_')[1]  #: keeping only annotator name"
        pairwise_kappas.append(cohen_kappa_score(product_reviews[annotator1], product_reviews[annotator2]))
        annotators.append(f"{annotator1_name}_{annotator2_name}")  #: combining annotator pairs

#: mean Kappa value
mean_kappa = np.mean(pairwise_kappas)


#: bar plot for pairwise Kappa scores
plt.figure(figsize=(10, 4))
colors = sns.color_palette("pastel")
ax = sns.barplot(x=annotators, y=pairwise_kappas, palette=colors)

#: adding data labels on the bars
for p in ax.patches:
    height = p.get_height()
    height = p.get_height()
    xytext = (0, -10) if height > 0.95 else (0, 10)     #: adjusting bar top threshold as needed

    ax.annotate(f"{height:.2f}", (p.get_x() + p.get_width() / 2., height),
                ha='center', va='center', fontsize=12, color='black', xytext=xytext,
                textcoords='offset points')

plt.title("Pairwise Cohen's Kappa Scores", fontsize=16)
plt.xlabel('Annotator Pairs', fontsize=14)
plt.ylabel("Cohen's Kappa Score", fontsize=14)
plt.ylim(0, 1)  #: y-axis range to [0, 1], as per kappa range

#: x-axis labels
plt.xticks(rotation=0, ha='center', fontsize=12)
plt.gca().xaxis.set_tick_params(pad=6)  #: spacing between labels

#: grid lines
ax.yaxis.grid(False)
ax.set_axisbelow(True)
plt.tight_layout()
plt.show()


#: assigning sentiment using majority vote
majority_sentiments = product_reviews[annotator_columns].mode(axis=1)[0]
product_reviews['Sentiment'] = majority_sentiments

#: occurrences of each class
class_labels_order = ['StronglyNegative', 'Negative', 'SlightlyNegative', 'Neutral',
                      'SlightlyPositive', 'Positive', 'StronglyPositive']
class_counts = product_reviews['Sentiment'].value_counts().reindex(class_labels_order)

#: bar plot for class distribution
plt.figure(figsize=(10, 6))
colors = sns.color_palette("pastel")
ax = class_counts.plot(kind='bar', color=colors)
plt.title('Class Distribution', fontsize=16)
plt.xlabel('Sentiment Class', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(rotation=45, ha='right', fontsize=12)
plt.yticks(fontsize=12)

#: grid lines
ax.yaxis.grid(False)
ax.set_axisbelow(True)
#: adding data labels on the bars
for p in ax.patches:
    ax.annotate(f"{p.get_height()}", (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=12, color='black', xytext=(0, 10),
                textcoords='offset points')

plt.ylim(top=class_counts.max() + 50)  #: setting margin as needed
plt.tight_layout()
plt.show()

# import re

# def removeNonBengaliCharacters(text):
#     # Define a regular expression pattern to match Bengali characters
#     bengali_pattern = re.compile('[\u0980-\u09FF\s]+')
#     # Use the regular expression to filter out non-Bengali characters
#     return ''.join(re.findall(bengali_pattern, text))

# product_reviews['Review'] = product_reviews['Review'].apply(removeNonBengaliCharacters)
# display(product_reviews)

import re   #: to work with regular expressions
def emoticonRemoval(review):
    #: remove emoticon by creating a pattern with regular expressions
    emoticon_pattern = re.compile("["
                        u"\U0001F600-\U0001F64F"  #: emoticons
                        u"\U0001F300-\U0001F5FF"  #: symbols & pictographs
                        u"\U0001F680-\U0001F6FF"  #: transport & map symbols
                        u"\U0001F1E0-\U0001F1FF"  #: flags (iOS)
                        u"\U00002500-\U00002BEF"  #: chinese characters
                        u"\U00002702-\U000027B0"
                        u"\U00002702-\U000027B0"
                        u"\U000024C2-\U0001F251"
                        u"\U0001f926-\U0001f937"
                        u"\U00010000-\U0010ffff"
                        u"\u2640-\u2642"
                        u"\u2600-\u2B55"
                        u"\u200d"
                        u"\u23cf"
                        u"\u23e9"
                        u"\u231a"
                        u"\ufe0f"  #: dingbats
                        u"\u3030"
                        "]+", flags=re.UNICODE)
    return emoticon_pattern.sub(r'', str(review))

product_reviews['Review'] = product_reviews['Review'].apply(emoticonRemoval)
display(product_reviews)

import re   #: to work with regular expressions
def urlRemoval(review):
    #: remove URLs with regular expressions
    url_pattern = re.compile(r'http\S+|www\S+')
    return url_pattern.sub('', review)

product_reviews['Review'] = product_reviews['Review'].apply(urlRemoval)
display(product_reviews)

import re   #: to work with regular expressions
def htmlTagRemoval(review):
    #: remove HTML tags
    html_pattern = re.compile(r'<.*?>')
    return html_pattern.sub('', review)

product_reviews['Review'] = product_reviews['Review'].apply(htmlTagRemoval)
display(product_reviews)

def punctuationRemoval(review):
    #: define punctuations to exclude from review
    punctuations = '''````£|¢|Ñ+-*/=EROero৳০১২৩৪৫৬৭৮৯012–34567•89।।!()-[]{};:'"“\’,<>./?@#$%^&*_~‘—॥”‰￰৷￰'''

    #: remove any punctuation from review that matches with any of these punctuations
    return ''.join(char for char in review if char not in punctuations)

product_reviews['Review'] = product_reviews['Review'].apply(punctuationRemoval)
display(product_reviews)

right_words = pd.read_csv('/content/dataset/RightWords.csv')
right_words = right_words['RightWord'].tolist()
wrong_words = pd.read_csv('/content/dataset/WrongWords.csv')
wrong_words = wrong_words['WrongWord'].tolist()

import numpy as np      #: to manipulate data

def bengaliEditDistance(word, correct_word):
    m = len(word)
    n = len(correct_word)

    #: create a matrix to store the edit distances
    dp = np.zeros((m + 1, n + 1), dtype=int)

    #: initialize the first row and column
    for i in range(m + 1):
        dp[i, 0] = i
    for j in range(n + 1):
        dp[0, j] = j

    #: compute the edit distances
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if word[i - 1] == correct_word[j - 1]:
                dp[i, j] = dp[i - 1, j - 1]
            else:
                dp[i, j] = min(dp[i - 1, j], dp[i, j - 1], dp[i - 1, j - 1]) + 1

    return dp[m, n]


def correctSpelling(word):
    min_distance = float('inf')
    corrected_word = word

    #: find the word with the minimum edit distance
    for correct_word in right_words:
        distance = bengaliEditDistance(word, correct_word)
        if distance < min_distance:
            min_distance = distance
            corrected_word = correct_word

    return corrected_word

def spellingCorrection(review):
    #: if any word from review matches with wrongWords, then replace the word from rightWords list
    return " ".join(correctSpelling(word) if word in wrong_words else word for word in str(review).split())

product_reviews['Review'] = product_reviews['Review'].apply(spellingCorrection)
display(product_reviews)

import re
def consecutiveDuplicateWordRemoval(review):
    #: remove any consecutive duplicate word from review
    return ' '.join([word for i, word in enumerate(review.split()) if i == 0 or word != review.split()[i-1] or i == len(review.split())-1])

product_reviews['Review'] = product_reviews['Review'].apply(consecutiveDuplicateWordRemoval)
display(product_reviews)

stopwords = pd.read_csv('/content/dataset/StopWords.csv')
stopwords = stopwords['StopWord'].tolist()

def stopWordRemoval(review):
    #: remove any word from review that is available in stopwords list
    return ' '.join([word for word in str(review).split() if word not in stopwords])

product_reviews['Review'] = product_reviews['Review'].apply(stopWordRemoval)
display(product_reviews)

!pip install bnlp_toolkit -q    #: to use stopwords of bnlp
from bnlp import BengaliCorpus as corpus

def stopwordRemovalUsingBNLP(review):
    #: remove any word from review that is available in stopwords_BNLP list
    return ' '.join([word for word in str(review).split() if word not in corpus.stopwords])

product_reviews['Review'] = product_reviews['Review'].apply(stopwordRemovalUsingBNLP)
display(product_reviews)

# !pip install bnltk -q
# from bnltk.stemmer import BanglaStemmer

# stemmer = BanglaStemmer()

# def wordStem(review):
#     return ' '.join([stemmer.stem(word) for word in review.split()])

# product_reviews['Review'] = product_reviews['Review'].apply(wordStem)
# display(product_reviews)

#: separate input and target
reviews = product_reviews['Review'].tolist()  #: input
sentiments = product_reviews['Sentiment'].tolist()    #: target
display(reviews)

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.ensemble import BaggingClassifier, VotingClassifier
from sklearn.dummy import DummyClassifier

#: define the classifiers
# classifiers = {
#     'Logistic Regression': LogisticRegression(C=1.0, solver='lbfgs'),
#     'Multinomial Naive Bayes': MultinomialNB(alpha=1.0),
#     'Support Vector Classifier': SVC(C=1, kernel='rbf', gamma=0.001, probability=True),
#     'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=None),
#     'AdaBoost': AdaBoostClassifier(n_estimators=50, learning_rate=1.0),
#     'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.01, max_depth=3),
#     'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, metric='minkowski'),
#     'MLP Neural Network': MLPClassifier(hidden_layer_sizes=(100,), activation='relu'),
#     'Decision Tree': DecisionTreeClassifier(max_depth=None, min_samples_split=2),
#     'Extra Tree': ExtraTreeClassifier(),
#     'Linear Discriminant Analysis': LinearDiscriminantAnalysis(solver='svd', shrinkage=None),
#     'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(reg_param=0.0),
#     'Gaussian Process': GaussianProcessClassifier(kernel=None, random_state=None),
#     'Bagging': BaggingClassifier(base_estimator=None, n_estimators=10),
#     'Dummy': DummyClassifier(strategy='stratified')
# }
classifiers = {
    'Logistic Regression': LogisticRegression(),
    'Multinomial Naive Bayes': MultinomialNB(),
    'Support Vector Classifier': SVC(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'MLP Neural Network': MLPClassifier(),
    'Decision Tree': DecisionTreeClassifier(),
    'Bagging': BaggingClassifier(),
}
classifier_order = list(classifiers.keys())

def plotMetrics(feature_name, metrics):
    metric_names = metrics[list(metrics.keys())[0]].keys()      #: metrics to be plotted

    # Define a custom color palette with the same length as classifier_order
    custom_palette = sns.color_palette("pastel", n_colors=len(classifier_order))

    for metric_name in metric_names:
        data = []
        for classifier_name in classifier_order:   #: Iterate through classifiers in the specified order
            if metric_name not in metrics[classifier_name]:
                continue
            data.append({'Classifier': classifier_name, metric_name: metrics[classifier_name][metric_name]})
        df_metric = pd.DataFrame(data)      #: DataFrame from the gathered data

        #: plot figure
        plt.figure(figsize=(10, 6))
        ax = sns.barplot(x='Classifier', y=metric_name, data=df_metric, order=classifier_order, palette=custom_palette)
        #: title and axis labels
        plt.title(f'{metric_name} Comparison for Different Classifiers with {feature_name}', fontsize=16)
        plt.xlabel('Classifier', fontsize=14)
        plt.ylabel(metric_name, fontsize=14)
        #: rotating x-axis labels for better visibility
        plt.xticks(rotation=45, ha='right', fontsize=12)
        plt.yticks(fontsize=12)
        #: excluding y-axis grid lines and set them below the bars
        ax.yaxis.grid(False)
        ax.set_axisbelow(True)

        #: data labels on the bars
        for p in ax.patches:
            ax.annotate(f"{p.get_height():.2f}", (p.get_x() + p.get_width() / 2., p.get_height()),
                        ha='center', va='center', fontsize=12, color='black', xytext=(0, 10),
                        textcoords='offset points')

        plt.ylim(top=df_metric[metric_name].max() + 0.1)    #: y-axis limits to include a small margin
        plt.tight_layout()      #: ensuring the layout is tight and display the plot
        plt.show()

#: importing different evaluation metrics
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix
import matplotlib.pyplot as plt     #: for ploting figures
import seaborn as sns               #: for visualization

def evaluateClassifier(X_train, y_train, X_test, y_test):
    classifiers_metrics = {}

    for classifier_name, classifier in classifiers.items():
        classifier.fit(X_train, y_train)
        y_pred = classifier.predict(X_test)

        print(f"\t{classifier_name} Metrics:")
        metrics = {}

        #: evaluation metrics
        accuracy = accuracy_score(y_test, y_pred)
        error_rate = 1 - accuracy
        sensitivity = recall_score(y_test, y_pred, average='weighted')
        confusion = confusion_matrix(y_test, y_pred)
        specificity = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1])
        precision = precision_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')

        metrics = {
            'Accuracy': accuracy,
            'Error Rate': error_rate,
            'Sensitivity': sensitivity,
            'Specificity': specificity,
            'Precision': precision,
            'F1 Score': f1
        }
        for metric_name, metric_value in metrics.items():
            print(f"\t\t{metric_name}: {metric_value*100:.2f}%")

        #: confusion matrix with specific class label order
        plt.figure(figsize=(10, 8))
        confusion_normalized = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]  #: normalize confusion matrix

        heatmap = sns.heatmap(confusion_normalized, annot=True, fmt=".2f", cmap="YlGnBu", annot_kws={'size': 12},
                            xticklabels=class_labels_order, yticklabels=class_labels_order)
        plt.title(f'Normalized Confusion Matrix - {classifier_name}', fontsize=16)
        plt.xlabel('Predicted', fontsize=14)
        plt.ylabel('True', fontsize=14)
        plt.xticks(rotation=45, ha='right', fontsize=12)
        plt.xticks(fontsize=12)

        #:  color legend
        colorbar = heatmap.collections[0].colorbar
        colorbar.set_label('Normalized Values', rotation=90, labelpad=15)
        plt.tight_layout()
        plt.show()

        classifiers_metrics[classifier_name] = metrics
    return classifiers_metrics

def evaluateAndPlot(feature_name, X_train, y_train, X_test, y_test):
    print("Evaluating Classifiers:")    #: evaluation metrics for each classifier
    classifiers_metrics = evaluateClassifier(X_train, y_train, X_test, y_test)
    print("Plotting Metrics:")          #: comparison of metrics among all classifiers
    plotMetrics(feature_name, classifiers_metrics)
    return classifiers_metrics

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

#: split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(reviews, sentiments, test_size=0.3, random_state=40)

#: initialize the TF-IDF vectorizer
vectorizer = TfidfVectorizer()

#: transform the training and testing data
X_train_tfidf = vectorizer.fit_transform(X_train).toarray()
X_test_tfidf = vectorizer.transform(X_test).toarray()

#: evaluate and plot for TF-IDF
print("Evaluation and Comparison for TF-IDF:")
tfidf_metrics = evaluateAndPlot("TF-IDF", X_train_tfidf, y_train, X_test_tfidf, y_test)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(reviews, sentiments, test_size=0.3, random_state=40)

# Initialize the TF-IDF vectorizer with n-grams and increased max_features
vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)

# Transform the training and testing data
X_train_tfidf = vectorizer.fit_transform(X_train).toarray()
X_test_tfidf = vectorizer.transform(X_test).toarray()

#: evaluate and plot for TF-IDF with N-Gram
print("Evaluation and Comparison for TF-IDF and N-Gram:")
evaluateAndPlot("TF-IDF and N-Gram", X_train_tfidf, y_train, X_test_tfidf, y_test)

import numpy as np
from gensim.models import Word2Vec
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

#: tokenize the pre-processed reviews into list of words
tokenized_reviews = [review.split() for review in reviews]

#: train Word2Vec model on the tokenized reviews
model = Word2Vec(tokenized_reviews, vector_size=100, window=5, min_count=1, workers=4)

#: function to generate feature vectors for each review
def get_feature_vector(review):
    feature_vector = np.zeros(model.vector_size)
    n_words = 0
    for word in review:
        if word in model.wv:
            feature_vector = np.add(feature_vector, model.wv[word])
            n_words += 1
    if n_words > 0:
        feature_vector = np.divide(feature_vector, n_words)
    return feature_vector

#: generate feature vectors for all reviews
feature_vectors = np.array([get_feature_vector(review) for review in tokenized_reviews])

#: normalize the feature vectors
scaler = MinMaxScaler()
feature_vectors = scaler.fit_transform(feature_vectors)

#: split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(feature_vectors, sentiments, test_size=0.3, random_state=18)

#: evaluate and plot for Word2Vec
print("Evaluation and Comparison for Word2Vec:")
evaluateAndPlot("Word2Vec", X_train, y_train, X_test, y_test)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split

#: split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(reviews, sentiments, test_size=0.3, random_state=40)

#: initialize and fit the CountVectorizer
vectorizer = CountVectorizer()
X_train_bow = vectorizer.fit_transform(X_train).toarray()
X_test_bow = vectorizer.transform(X_test).toarray()

#: evaluate and plot for CountVectorizer
print("Evaluation and Comparison for CountVectorizer:")
evaluateAndPlot("CountVectorizer", X_train_bow, y_train, X_test_bow, y_test)

import matplotlib.pyplot as plt

# ClaClassifierssifier names
classifiers = [
    "Logistic Regression", "Multinomial Naive Bayes", "Support Vector Classifier",
    "Random Forest", "AdaBoost", "Gradient Boosting", "K-Nearest Neighbors",
    "MLP Neural Network", "Decision Tree", "Bagging"
]

# Accuracy values for Word2Vec
accuracy_word2vec = [
    40.88, 38.68, 42.86, 42.42, 26.81, 37.36, 31.21, 39.78, 28.79, 37.58
]

# Accuracy values for TF-IDF
accuracy_tfidf = [
    42.42, 41.76, 45.05, 41.10, 40.00, 41.10, 35.82, 38.46, 38.90, 41.10
]

# Accuracy values for TF-IDF and N-Gram
accuracy_tfidf_ngram = [
    45.71, 41.32, 44.84, 40.66, 36.70, 43.96, 36.92, 37.58, 39.12, 40.66
]

# Creating subplots
fig, ax = plt.subplots()

# Plotting data
ax.plot(classifiers, accuracy_word2vec, marker='o', label='Word2Vec')
ax.plot(classifiers, accuracy_tfidf, marker='o', label='TF-IDF')
ax.plot(classifiers, accuracy_tfidf_ngram, marker='o', label='TF-IDF and N-Gram')

# Adding labels and title
ax.set_xlabel('Classifiers')
ax.set_ylabel('Accuracy')
ax.set_title('Accuracy Comparison of Different Classifiers')
ax.legend()

# Rotating x-axis labels for better visibility
plt.xticks(rotation=45, ha="right")

# Display the plot
plt.tight_layout()
plt.show()